{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95da603f-f0c3-47b8-90c1-9cf1654e1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_retrieval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24f1fe7e-b354-4c35-815e-2795ec06f1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the interaction file. Length of the list: 11628\n",
      "Number of questions collected from interaction file: 11628\n",
      "Saving interaction file with question only ...  \n",
      "==== Now filtering table_QA dataset ====\n",
      "Length before filtering: 11628\n",
      "Length after filtering: 8768\n"
     ]
    }
   ],
   "source": [
    "merged_nq_table_data_loc = \"/home/deokhk/research/MultiQA/dataset/NQ_tables/interactions/merged_interaction.json\"\n",
    "dpr_nq_train_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/nq-train.json\"\n",
    "dpr_nq_dev_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/nq-dev.json\"\n",
    "original_nq_train_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/qas/nq-train.csv\"\n",
    "original_nq_dev_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/qas/nq-dev.csv\"\n",
    "original_nq_test_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/qas/nq-test.csv\"\n",
    "\n",
    "table_q_list = generate_retrieval_dataset.extract_q_from_interaction_file_and_save(merged_nq_table_data_loc)\n",
    "filtered_table_q_list = generate_retrieval_dataset.filter_and_save_table_qa_dataset(table_q_list, original_nq_train_data_loc, original_nq_dev_data_loc, merged_nq_table_data_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e76e87-65fd-4a7d-8df1-c353d8b6f0bc",
   "metadata": {},
   "source": [
    "## Experiment 1: Filtered interaction에 question이 중복인 녀석들이 존재하는것 같음. 이 녀석들을 어떻게 처리해야되는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c48b16db-613c-4131-afb8-a271dc7b8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선, 각 interaction data의 format부터 볼까..\n",
    "import json\n",
    "with open(\"/home/deokhk/research/MultiQA/dataset/NQ_tables/interactions/filtered_interaction.json\", 'r') as f:\n",
    "    filtered_interaction = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc746d91-962a-4a17-8e9a-940a26ebbd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list form: 8822, set form: 8768\n"
     ]
    }
   ],
   "source": [
    "mi_list_form = []\n",
    "for it_object in filtered_interaction:\n",
    "    mi_list_form.append(it_object[\"questions\"][0][\"originalText\"])\n",
    "print(f\"list form: {len(mi_list_form)}, set form: {len(set(mi_list_form))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d75947db-b95f-4d47-99af-0941ba685e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who has the most water in the world'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"questions\"][0][\"originalText\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "93866730-895a-4d12-9799-e918f4b0b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the life expectancy of an english mastiff\n",
      "what percent of gdp is spent on education in india\n",
      "who played the chicago cubs in the world series last year\n",
      "who played in the nba finals in 1994\n",
      "who has the most wins in college history\n",
      "where do the majority of apples come from\n",
      "who has won the second most world series\n",
      "how many runs sachin scored in his odi debut\n",
      "who did the cubs play in the nlcs last year\n",
      "who has the best winning percentage in college football\n",
      "who won the baseball world series in 2017\n",
      "what age do king charles cavaliers live to\n",
      "how much of the gdp does nepal spend on education\n",
      "who produces the most apples in the world\n",
      "whats the latest version of google play store\n",
      "who won the 2017 world series of baseball\n",
      "how many passing yards does aaron rodgers have in his career\n",
      "who has won the world series the most\n",
      "where does the full stop go with speech marks\n",
      "average life expectancy for a west highland terrier\n",
      "who won the fight with floyd mayweather and pacquiao\n",
      "who won the ncaa basketball championship in 2015\n",
      "who did the cubs beat in the 2016 world series\n",
      "who did the dodgers face in 1988 world series\n",
      "how much does us spend on education gdp\n",
      "how many republicans and how many democrats are in the senate\n",
      "what is the average litter size for a chihuahua\n",
      "who did the astros beat in the world series\n",
      "who did louisville beat for the 2013 national championship\n",
      "last time an nhl team came back from 3-0 in playoffs\n",
      "who won the 2017 qatar motogp grand prix\n",
      "who has won the most world series in the national league\n",
      "who did the detroit pistons beat in the nba finals\n",
      "how many goals did david beckham scored for real madrid\n",
      "how many career touchdowns does julio jones have\n",
      "who won the 100 meter dash in the 2016 olympics\n",
      "who is leading the world series in baseball\n",
      "who won medals in mens skating 2018 olympics\n",
      "who did the warriors play last year in the finals\n",
      "who did kobe bryant beat in the finals\n",
      "who won the first ever basketball gold medal\n",
      "who do the dbacks play in the wild card game\n",
      "what is the average lifespan of a newfoundland\n",
      "when did pioneer 10 leave the solar system\n",
      "who did the cubs beat last year in the world series\n",
      "who is the captain of the toronto raptors\n",
      "largest producer of apple in the world 2017\n",
      "how many puppies do olde english bulldogs have\n",
      "who won the sec championship in football this year\n",
      "how many puppies can a newfoundland dog have\n",
      "who has the best winning percentage in college football history\n",
      "the point in the moons orbit when its farthest away from earth is called\n",
      "who did the cubs play in the first round of the playoffs in 2016\n",
      "who won gold medal in high jump rio\n"
     ]
    }
   ],
   "source": [
    "question_that_appeared = set()\n",
    "for it_object in filtered_interaction:\n",
    "    q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "    if q in question_that_appeared:\n",
    "        print(q)\n",
    "    else:\n",
    "        question_that_appeared.add(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c7066-3392-4018-bdb9-1514694cfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_that_appeared = set()\n",
    "for it_object in filtered_interaction:\n",
    "    q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "    if q==\"what percent of gdp is spent on education in india\":\n",
    "        print(\"=====================================\")\n",
    "        print(it_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "27844af0-442b-4c59-8108-718613d8f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import extract_table_dataframe_from_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "43b08eb4-0b72-4e7e-8044-b2945a7dc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_obj_list = []\n",
    "for it_object in filtered_interaction:\n",
    "    q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "    if q==\"what percent of gdp is spent on education in india\":\n",
    "        duplicated_obj_list.append(it_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7300ff48-2b55-4d27-9824-860d391af0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Expenditure on education (% of GDP)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17...</td>\n",
       "      <td>Country Expenditure on education (% of GDP) Ye...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rank</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1990</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1990</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Country  \\\n",
       "0    Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17...   \n",
       "1                                                 Rank   \n",
       "2                                                    1   \n",
       "3                                                    2   \n",
       "4                                                    3   \n",
       "..                                                 ...   \n",
       "388                                   Papua New Guinea   \n",
       "389                                         San Marino   \n",
       "390                              Sao Tome and Principe   \n",
       "391                                       Turkmenistan   \n",
       "392                                             Tuvalu   \n",
       "\n",
       "                   Expenditure on education (% of GDP)  Year Source  \n",
       "0    Country Expenditure on education (% of GDP) Ye...               \n",
       "1                                                                    \n",
       "2                                                                    \n",
       "3                                                                    \n",
       "4                                                                    \n",
       "..                                                 ...   ...    ...  \n",
       "388                                               n.a.  n.a.    [1]  \n",
       "389                                                3.2  1990    [1]  \n",
       "390                                                  6  2012    [2]  \n",
       "391                                                  3  2012    [2]  \n",
       "392                                                7.6  1990    [1]  \n",
       "\n",
       "[393 rows x 4 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_table_dataframe_from_interaction(duplicated_obj_list[0])\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "24e04f27-6965-45e2-8821-038e6e6cdf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Expenditure on education (% of GDP)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Timor-Leste</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2012</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2000</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cuba</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2012</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lesotho</td>\n",
       "      <td>13</td>\n",
       "      <td>2012</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1990</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1990</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Country Expenditure on education (% of GDP)  Year Source\n",
       "0              Timor-Leste                                10.1  2012    [1]\n",
       "1      Trinidad and Tobago                                 3.8  2000    [1]\n",
       "2         Marshall Islands                                14.6  2000    [1]\n",
       "3                     Cuba                                12.9  2012    [1]\n",
       "4                  Lesotho                                  13  2012    [1]\n",
       "..                     ...                                 ...   ...    ...\n",
       "190       Papua New Guinea                                n.a.  n.a.    [1]\n",
       "191             San Marino                                 3.2  1990    [1]\n",
       "192  Sao Tome and Principe                                   6  2012    [2]\n",
       "193           Turkmenistan                                   3  2012    [2]\n",
       "194                 Tuvalu                                 7.6  1990    [1]\n",
       "\n",
       "[195 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_table_dataframe_from_interaction(duplicated_obj_list[1])\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "814beb95-dabf-4f04-9b18-62790845f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n"
     ]
    }
   ],
   "source": [
    "question_that_appeared = set()\n",
    "duplicated_questions = []\n",
    "for it_object in filtered_interaction:\n",
    "    q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "    if q in question_that_appeared:\n",
    "        duplicated_questions.append(q)\n",
    "    else:\n",
    "        question_that_appeared.add(q)\n",
    "\n",
    "question_count = []\n",
    "for elem in duplicated_questions:\n",
    "    question_count.append(duplicated_questions.count(elem))\n",
    "print(set(question_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ae5c6ae4-093c-4975-b6aa-a9d462bad72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is duplication. dictionary form: 87920, list form: 87925\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Filtered interaction에 속하는 question이 중복된 QA pair에 대하여, NQ_open에서는 어떻게 처리하고 있을지 확인해보자.\n",
    "nq_open_train_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/qas/nq-train.csv\"\n",
    "nq_open_dev_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/qas/nq-dev.csv\"\n",
    "original_nq_open_dict = {}\n",
    "list_form_length_count = 0\n",
    "with open(nq_open_train_loc, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\"\\t\")\n",
    "    for row in reader:\n",
    "        question = row[0]\n",
    "        answer = row[1]\n",
    "        original_nq_open_dict[question.strip()] = answer\n",
    "        list_form_length_count+=1\n",
    "\n",
    "with open(nq_open_dev_loc, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\"\\t\")\n",
    "    for row in reader:\n",
    "        question = row[0]\n",
    "        original_nq_open_dict[question.strip()] = answer\n",
    "        list_form_length_count+=1\n",
    "\n",
    "if(len(original_nq_open_dict) == list_form_length_count):\n",
    "    print(\"There are no duplicated question in NQ_open!\")\n",
    "else:\n",
    "    print(f\"There is duplication. dictionary form: {len(original_nq_open_dict)}, list form: {list_form_length_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "670d8c59-381e-45dc-9b6b-b7388265a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered interaction에 속하는 question이 중복된 QA pair에 대하여, NQ_open에서는 어떻게 처리하고 있을지 확인해보자.\n",
    "# Filtered interaction에 속하는 중복된 QA pair들에 대하여, 각 중복 QA pair들을 [(q_1, a_1), (q_1_dup, a_2)] 이런 형식으로 표현하자. 아 이러면 안될듯. {\"q1\":[a_1, a_2]} 이런식으로 해야겠는데? \n",
    "# 동일한 q_1에 대하여, NQ_open에서 [(q_1, a_1)] 형태로 표현하자.\n",
    "duplicated_qa_dict ={}\n",
    "# filtered interaction에 속하는 중복된 QA pair에 대하여 검사함.\n",
    "for it_object in filtered_interaction:\n",
    "    q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "    if q in duplicated_questions:\n",
    "        if q in duplicated_qa_dict:\n",
    "            answer = it_object[\"questions\"][0][\"answer\"][\"answerTexts\"]\n",
    "            duplicated_qa_dict[q] = duplicated_qa_dict[q] + answer\n",
    "        else:\n",
    "            duplicated_qa_dict[q] = it_object[\"questions\"][0][\"answer\"][\"answerTexts\"]\n",
    "\n",
    "# NQ_open에 속하는 애들..\n",
    "duplicated_nq_open_dict = {}\n",
    "with open(nq_open_train_loc, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\"\\t\")\n",
    "    for row in reader:\n",
    "        question = row[0].strip()\n",
    "        if question in duplicated_questions:\n",
    "            answer = row[1]\n",
    "            duplicated_nq_open_dict[question] = answer\n",
    "\n",
    "with open(nq_open_dev_loc, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\"\\t\")\n",
    "    for row in reader:\n",
    "        question = row[0].strip()\n",
    "        if question in duplicated_questions:\n",
    "            answer = row[1]\n",
    "            duplicated_nq_open_dict[question] = answer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702bd75-4b5c-4604-b2da-bfc24642d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in duplicated_qa_dict:\n",
    "    print(\"==== In filtered interaction ====\")\n",
    "    print(f\"{q} : {duplicated_qa_dict[q]}\")\n",
    "    print(\"==== In NQ_open ==== \")\n",
    "    print(f\"{q} : {duplicated_nq_open_dict[q]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2689a-ee19-4d9b-8551-17ad694da3db",
   "metadata": {},
   "source": [
    "## DPR training시 question이 Table qa pair와 overllap이 있는 경우, positive passage가 어떠한 형식으로 주어지는지 확인하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d3996-501e-4738-bb10-c8e6df5a5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtred interaction과 overlap되는 pair에 대하여, \n",
    "# Filtered interaction + 그리고 overllaped pair 하나를 표시하자.\n",
    "dpr_nq_train_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/nq-train.json\"\n",
    "dpr_nq_dev_data_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/nq-dev.json\"\n",
    "\n",
    "with open(dpr_nq_train_data_loc, 'r') as dpr_file:\n",
    "    dpr_data = json.load(dpr_file)\n",
    "    \n",
    "count = 0\n",
    "pos = int(input(\"Which position?\"))\n",
    "for data in dpr_data:\n",
    "    q = data[\"question\"].strip()\n",
    "    for it_object in filtered_interaction:\n",
    "        ft_q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "        if q == ft_q:\n",
    "            print(\"==== In DPR ====\")\n",
    "            print(data)\n",
    "            print(\"==== In Table dataset ====\")\n",
    "            print(it_object)\n",
    "            count +=1\n",
    "            break\n",
    "    if count == pos:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0b7e1-c68f-4640-94b4-8180b9f4f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original NQ data에서 정답이 table이나 infobox, list위에 있다고 표시된 경우, DPR에서는 어떻게 처리하고있는지, 그리고 filtered interaction에서는 어떻게 처리하고 있는지 각각 표시함.\n",
    "for data in dpr_data:\n",
    "    q = data[\"question\"].strip()\n",
    "    if q == \"who played in the nba finals in 1994\":\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "925784f0-b07f-46fe-ba1f-09edcae23cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Host</th>\n",
       "      <th>Winning Team</th>\n",
       "      <th>Captain</th>\n",
       "      <th>Head coach</th>\n",
       "      <th>Runner-up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>India</td>\n",
       "      <td>M S Dhoni</td>\n",
       "      <td>Lalchand Rajput</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>England</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Younis Khan</td>\n",
       "      <td>Intikhab Alam</td>\n",
       "      <td>Sri Lanka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>England</td>\n",
       "      <td>Paul Collingwood</td>\n",
       "      <td>Andy Flower</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>Darren Sammy</td>\n",
       "      <td>Ottis Gibson</td>\n",
       "      <td>Sri Lanka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>Lasith Malinga</td>\n",
       "      <td>Paul Farbrace</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>India</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>Darren Sammy</td>\n",
       "      <td>Phil Simmons</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year          Host Winning Team           Captain       Head coach  \\\n",
       "0  2007  South Africa        India         M S Dhoni  Lalchand Rajput   \n",
       "1  2009       England     Pakistan       Younis Khan    Intikhab Alam   \n",
       "2  2010   West Indies      England  Paul Collingwood      Andy Flower   \n",
       "3  2012     Sri Lanka  West Indies      Darren Sammy     Ottis Gibson   \n",
       "4  2014    Bangladesh    Sri Lanka    Lasith Malinga    Paul Farbrace   \n",
       "5  2016         India  West Indies      Darren Sammy     Phil Simmons   \n",
       "\n",
       "   Runner-up  \n",
       "0   Pakistan  \n",
       "1  Sri Lanka  \n",
       "2  Australia  \n",
       "3  Sri Lanka  \n",
       "4      India  \n",
       "5    England  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = 0\n",
    "for it_object in filtered_interaction:\n",
    "    q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "    if q == \"who won the last 20 over world cup\":\n",
    "        df = extract_table_dataframe_from_interaction(it_object)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbdff2-78ff-4147-ad16-03ee1d9f6e43",
   "metadata": {},
   "source": [
    "## Filtered_interaction에서 DPR에 이미 들어가 있는 QA pair는 제외하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f28161b9-e5b3-4658-aa9f-3b19aa06a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_qa_pair(dpr_train_loc, dpr_dev_loc, filtered_interaction):\n",
    "    with open(dpr_train_loc, 'r') as f:\n",
    "        dpr_train = json.load(f)\n",
    "    with open(dpr_dev_loc, 'r') as f:\n",
    "        dpr_dev = json.load(f)\n",
    "    \n",
    "    dpr_q = set()\n",
    "    for data in dpr_train:\n",
    "        dpr_q.add(data[\"question\"].strip())\n",
    "    for data in dpr_dev:\n",
    "        dpr_q.add(data[\"question\"].strip())\n",
    "    \n",
    "    duplicated_removed_interaction = []\n",
    "    print(f\"Number of QA pair before duplication removed: {len(filtered_interaction)}\")\n",
    "    for it_object in filtered_interaction:\n",
    "        q = it_object[\"questions\"][0][\"originalText\"].strip()\n",
    "        if q not in dpr_q:\n",
    "            duplicated_removed_interaction.append(it_object)\n",
    "    print(f\"Number of QA pair after duplication removed: {len(duplicated_removed_interaction)}\")\n",
    "    with open(\"/home/deokhk/research/MultiQA/dataset/NQ_tables/interactions/dup_removed_interaction.json\", \"w+\") as f:\n",
    "        json.dump(duplicated_removed_interaction, f)\n",
    "    print(\"Saving of duplicated_removed_interaction completed\")\n",
    "\n",
    "    return duplicated_removed_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe5b7fa9-ed39-4348-8737-4521da5895ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QA pair before duplication removed: 8822\n",
      "Number of QA pair after duplication removed: 5137\n",
      "Saving of duplicated_removed_interaction completed\n"
     ]
    }
   ],
   "source": [
    "dpr_train_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/nq-train.json\"\n",
    "dpr_dev_loc = \"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/retriever/nq-dev.json\"\n",
    "dup_removed_interaction = remove_duplicated_qa_pair(dpr_train_loc, dpr_dev_loc, filtered_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4f79f-8871-4e2f-b6bc-6aef49a1bca5",
   "metadata": {},
   "source": [
    "## Bert tokenizer demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8234c6e-4296-4b98-b9d9-f2471796447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word emebedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a new GPU![CLS] hey\n",
      "I have a new GPU! [CLS] hey\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\",additional_special_tokens=['[C_SEP]', '[R_SEP]'])\n",
    "sent = \"I have a new GPU![CLS] hey\"\n",
    "print(sent)\n",
    "r1= tokenizer.tokenize(sent)\n",
    "reconstructed = tokenizer.decode(tokenizer.convert_tokens_to_ids(r1))\n",
    "print(reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0feb89-13a1-4d33-b054-3176fa8057cc",
   "metadata": {},
   "source": [
    "## Table passage generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71089c-c333-4b0c-976b-b1b07fb8f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import json\n",
    "import csv\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def linearize_column(column_list):\n",
    "    linearized_column =\"\"\n",
    "    cl = len(column_list)\n",
    "    for i, column in enumerate(column_list):\n",
    "        linearized_column +=column\n",
    "        if i != cl-1:\n",
    "            linearized_column+=\" \"\n",
    "    return linearized_column\n",
    "        \n",
    "    \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", additional_special_tokens = ['[C_SEP]', '[R_SEP]'])\n",
    "table_data_loc = \"/home/deokhk/research/MultiQA/dataset/NQ_tables/tables/tables.jsonl\"\n",
    "with open(table_data_loc, 'r') as table_file:\n",
    "    table_datas = list(table_file)\n",
    "\n",
    "count = 0\n",
    "psg_count = 21015325 # Since the last number of wikipedia split is 21015324\n",
    "\n",
    "f = open(\"/home/deokhk/research/MultiQA/model/DPR/dpr/downloads/data/wikipedia_split/table_w100.tsv\", \"wt\")\n",
    "tsv_writer = csv.writer(f, delimiter='\\t')\n",
    "\n",
    "for table in table_datas:\n",
    "    print(table)\n",
    "    table = json.loads(table)\n",
    "    title = table[\"documentTitle\"]\n",
    "    columns =[]\n",
    "    for i, column in enumerate(table[\"columns\"]):\n",
    "        columns.append(column[\"text\"])\n",
    "        if i != len(table[\"columns\"])-1:\n",
    "            columns.append(\"[C_SEP]\")\n",
    "    linearized_column = linearize_column(columns)\n",
    "\n",
    "    linearized_value = \"\"\n",
    "    rows = table[\"rows\"]\n",
    "    for i, row in enumerate(rows):\n",
    "        row_value = row[\"cells\"]\n",
    "        for j, value in enumerate(row_value):\n",
    "            linearized_value += value[\"text\"] \n",
    "            if j != len(row_value)-1:\n",
    "                linearized_value += \"[R_SEP]\"\n",
    "        if i != len(rows)-1:\n",
    "            # Since \"\\n\" is considered as whitespace, we first set delimter for each sentence as \"[CLS]\"\n",
    "            # And replace it to \"\\n\" afterward.\n",
    "            linearized_value += \"[CLS]\"\n",
    "    linearized_value = tokenizer.tokenize(linearized_value)\n",
    "    \n",
    "    # split the linearized value into passages, each with 100 token.\n",
    "    vlen = len(linearized_value)\n",
    "    quotient = vlen // 100\n",
    "    remainder = vlen % 100\n",
    "    psg_list = []\n",
    "    \n",
    "    if quotient == 0:\n",
    "        psg_list.append(linearized_value[0:remainder])\n",
    "    else:\n",
    "        for i in range(quotient+1):\n",
    "\n",
    "            psg_list.append(linearized_value[i*100:(i+1)*100])\n",
    "            if i == quotient and remainder:\n",
    "                psg_list.append(linearized_value[(i+1)*100:(i+1)*100 + remainder])\n",
    "    \n",
    "    for psg in psg_list:\n",
    "        psg = tokenizer.convert_tokens_to_string(psg)\n",
    "        psg = psg.replace(\"[CLS]\", \"\\n\")\n",
    "        tsv_writer.writerow([psg_count, linearized_column + \"[SEP]\" + psg, title])\n",
    "        psg_count+=1\n",
    "    \n",
    "        \n",
    "    count+=1\n",
    "    if count == 2:\n",
    "        break\n",
    "f.close()\n",
    "    #print(len(linearized_value))\n",
    "    #count+=1\n",
    "    #if count==20:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e34fa3a-a190-47be-b014-345f18d159b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Return splitted table passages.\n",
    "# Form: tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8014aed-a298-45ca-8af5-dfe874de5e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearized_value = list(range(25))\n",
    "quotient = len(linearized_value) // 10\n",
    "remainder = len(linearized_value) % 10\n",
    "splitted_list = []\n",
    "if quotient == 0:\n",
    "    splitted_list.append(linearized_value[0:remainder])\n",
    "else:\n",
    "    for i in range(quotient):\n",
    "        splitted_list.append(linearized_value[i*10:(i+1)*10])\n",
    "        if i == quotient-1 and remainder:\n",
    "            splitted_list.append(linearized_value[(i+1)*10: (i+1)*10 + remainder])\n",
    "\n",
    "splitted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef13ec42-739e-41d6-b274-c42997371960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey \\n me'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Hey [CLS] me\"\n",
    "a.replace(\"[CLS]\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "540da0fa-3597-48b5-9e3a-baec50799a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word emebedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "b_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", additional_special_tokens = ['[C_SEP]', '[R_SEP]'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4956a4-b6ec-4995-9749-2e76155cbe54",
   "metadata": {},
   "source": [
    "## Generate table retrieval data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00c107-a97c-435d-930f-b0e0ede6b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\", additional_special_tokens = ['[C_SEP]', '[V_SEP]', '[R_SEP]'])\n",
    "\n",
    "for it_object in dup_removed_interaction:\n",
    "    table = it_object[\"table\"]\n",
    "    title = it_object[\"title\"]\n",
    "    question = it_object[\"questions\"][0][\"originalText\"]\n",
    "    answers = it_object[\"questions\"][0][\"answer\"][\"answerTexts\"]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f53cd-c1c5-4d9f-8892-c2dd5f376876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
